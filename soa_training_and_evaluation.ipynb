{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9d03f0-95bf-4cfb-93df-6a765bb9ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "import hashlib\n",
    "from skimage.transform import resize\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from src.soa_preprocessing import extract_subcubes, compute_subcubes_count, reconstruct_image, evaluate_dice_new, plot_3d_interactive, evaluateSegmentation\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.networks.nets import VNet\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c077ec-b98e-47bc-ad37-4f0468319ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_threshold = 0.5 \n",
    "using_decomp = True\n",
    "using_aug = False \n",
    "m_choice = 0 # from 0 to 3 (model choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccd1263-6c25-4535-9f2f-0a15db3e84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if m_choice == 0:\n",
    "    model = VNet(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1\n",
    "    ).cuda()\n",
    "\n",
    "elif m_choice == 1:\n",
    "    model = SwinUNETR(\n",
    "        img_size=target_size,  \n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        feature_size=48,\n",
    "        use_checkpoint=True,\n",
    "        use_v2=True\n",
    "    ).cuda()\n",
    "\n",
    "elif m_choice == 2:\n",
    "    model = BasicUNetPlusPlus(\n",
    "        spatial_dims=3,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        features=(16, 32, 64, 128, 256, 16)  \n",
    "    ).cuda()\n",
    "\n",
    "elif m_choice == 2:\n",
    "    model = SwinUNETR(\n",
    "        img_size=target_size,  \n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        feature_size=48,\n",
    "        use_checkpoint=True,\n",
    "        use_v2=False\n",
    "    ).cuda()\n",
    "\n",
    "else:\n",
    "    print(\"No model selected!\")\n",
    "\n",
    "\n",
    "criterion = criterion = DiceLoss(include_background=False, to_onehot_y=False, sigmoid=True)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27acafb-5a54-4b17-bfd3-72ac968c5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, fold_idx, epochs=5):\n",
    "    \n",
    "    data_dict = # include dataset path here in .pt format, with torch.load()\n",
    "    \n",
    "    train_dataset = data_dict['train']\n",
    "    val_dataset = data_dict['val']\n",
    "\n",
    "    target_size = (64, 64, 64) if using_decomp else (128, 128, 128)\n",
    "\n",
    "    batch_size_train = 8 if using_decomp else 2\n",
    "    batch_size_val = 27 if using_decomp else 1\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size_val, shuffle=False)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"{datetime.now().strftime('%H:%M:%S')} | Starting new epoch...\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.cuda(), masks.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            if m_choice == 2:\n",
    "                outputs = outputs[0] \n",
    "            masks = masks.clamp(0, 1)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        if epoch % 4 == 0:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss\n",
    "            }\n",
    "            torch.save(checkpoint, f\"models/{m_choice}_fold{fold_idx}_epoch{epoch+1}_aug{using_aug}.pth\")\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            dice_scores = []\n",
    "            iou_scores = []\n",
    "            tnr_scores = []\n",
    "            tpr_scores = []\n",
    "            fdr_scores = []\n",
    "            i=0\n",
    "            for images, masks in val_loader: \n",
    "                images, masks = images.cuda(), masks.cuda()\n",
    "                outputs = model(images)\n",
    "                if m_choice == 2:\n",
    "                  outputs = outputs[0] \n",
    "                pred_masks = outputs.float().cpu().numpy()\n",
    "                masks = masks.cpu().numpy()\n",
    "                \n",
    "                if using_decomp == True:   \n",
    "                    pred_masks = reconstruct_image(pred_masks, (128,128,128,1), (64,64,64,1), 32)\n",
    "                    masks = reconstruct_image(masks, (128,128,128,1), (64,64,64,1), 32)\n",
    "                    \n",
    "\n",
    "                eval = evaluateSegmentation([masks], [np.copy(pred_masks)],t=bin_threshold, det_t=bin_threshold)\n",
    "\n",
    "                dice_score = eval[\"dice\"][0]\n",
    "                iou_score = eval[\"iou\"][0]\n",
    "                tnr_score = eval[\"tnr\"][0]\n",
    "                tpr_score = eval[\"tpr\"][0]\n",
    "                fdr_score = eval[\"fdr\"][0]\n",
    "                \n",
    "                iou_scores.append(iou_score)\n",
    "                tnr_scores.append(tnr_score)\n",
    "                tpr_scores.append(tpr_score)\n",
    "                fdr_scores.append(fdr_score)\n",
    "                dice_scores.append(dice_score)\n",
    "                i+=1\n",
    "                \n",
    "            mean_dice = np.mean(dice_scores)\n",
    "            mean_iou = np.mean(iou_scores)\n",
    "            mean_tnr = np.mean(tnr_scores)\n",
    "            mean_tpr = np.mean(tpr_scores)\n",
    "            mean_fdr = np.mean(fdr_scores)\n",
    "            print(f\"Epoch {epoch+1}: DICE={mean_dice} | IOU={mean_iou} | TNR={mean_tnr} | TPR={mean_tpr} | FDR={mean_fdr}\")\n",
    "            scheduler.step(mean_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dfb4e9-f7c1-4240-a252-d1169bd5588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_idx in range(5):\n",
    "    train(model, train_loader, val_loader, fold_idx, epochs=17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
